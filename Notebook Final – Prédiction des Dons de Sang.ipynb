{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74b5ee0-00ab-4018-9053-def788518bf7",
   "metadata": {},
   "source": [
    "# PrÃ©diction du Comportement des Donneurs de Sang\n",
    "\n",
    "Projet de fin d'annÃ©e â€“ ENSIAS BI&A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cfb21-cbd7-4f85-b580-007a4ccc0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppression des avertissements\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Librairies de preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (classification_report, accuracy_score, confusion_matrix, \n",
    "                           roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                           f1_score, precision_score, recall_score)\n",
    "\n",
    "# ModÃ¨les de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "print(\"âœ… Toutes les bibliothÃ¨ques ont Ã©tÃ© importÃ©es avec succÃ¨s!\")\n",
    "print(f\"ðŸ“… Session dÃ©marrÃ©e le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd0bda-d05b-4244-a3ea-9c1f89d9a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_inspect_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"âœ… Dataset chargÃ© avec succÃ¨s!\")\n",
    "        print(f\"ðŸ“Š Dimensions: {df.shape[0]} lignes Ã— {df.shape[1]} colonnes\\n\")\n",
    "        \n",
    "        # Affichage des informations de base\n",
    "        print(\"ðŸ” APERÃ‡U DES DONNÃ‰ES:\")\n",
    "        print(\"=\" * 50)\n",
    "        display(df.head())\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ INFORMATIONS GÃ‰NÃ‰RALES:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(df.info())\n",
    "        \n",
    "        print(\"\\nðŸ“Š STATISTIQUES DESCRIPTIVES:\")\n",
    "        print(\"=\" * 50)\n",
    "        display(df.describe(include='all'))\n",
    "        \n",
    "        print(\"\\nâŒ VALEURS MANQUANTES:\")\n",
    "        print(\"=\" * 50)\n",
    "        missing_data = df.isnull().sum()\n",
    "        missing_percent = (missing_data / len(df)) * 100\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Colonne': missing_data.index,\n",
    "            'Valeurs manquantes': missing_data.values,\n",
    "            'Pourcentage': missing_percent.values\n",
    "        }).sort_values('Valeurs manquantes', ascending=False)\n",
    "        \n",
    "        display(missing_df[missing_df['Valeurs manquantes'] > 0])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "\n",
    "# Chargement des donnÃ©es\n",
    "df = load_and_inspect_data(\"base1_nettoyee.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb1f12-9ede-419f-a632-9d8b197222a1",
   "metadata": {},
   "source": [
    "#  NETTOYAGE ET PRÃ‰PROCESSING AVANCÃ‰ DES DONNÃ‰ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74bed8-29ef-40b2-836f-1ba9bdf9cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_data_cleaning(df):\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"ðŸ§¹ NETTOYAGE DES DONNÃ‰ES EN COURS...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Suppression des doublons\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean.drop_duplicates(inplace=True)\n",
    "    duplicates_removed = initial_rows - len(df_clean)\n",
    "    print(f\"ðŸ”„ Doublons supprimÃ©s: {duplicates_removed}\")\n",
    "    \n",
    "    # 2. Gestion des valeurs manquantes\n",
    "    missing_before = df_clean.isnull().sum().sum()\n",
    "    df_clean.dropna(inplace=True)\n",
    "    missing_after = df_clean.isnull().sum().sum()\n",
    "    print(f\"âŒ Valeurs manquantes supprimÃ©es: {missing_before - missing_after}\")\n",
    "    \n",
    "    # 3. Normalisation des noms de villes (avec gestion d'erreurs)\n",
    "    if 'Ville  Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©' in df_clean.columns:\n",
    "        ville_mapping = {\n",
    "            'RABAT': 'Rabat', 'rabat': 'Rabat',\n",
    "            'Casa': 'Casablanca', 'casa': 'Casablanca', 'CASA': 'Casablanca',\n",
    "            'AGADIR': 'Agadir', 'agadir': 'Agadir',\n",
    "            'FES': 'FÃ¨s', 'fes': 'FÃ¨s', 'Fes': 'FÃ¨s',\n",
    "            'MARRAKECH': 'Marrakech', 'marrakech': 'Marrakech',\n",
    "            'TANGER': 'Tanger', 'tanger': 'Tanger'\n",
    "        }\n",
    "        df_clean['Ville  Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'] = df_clean['Ville  Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©'].replace(ville_mapping)\n",
    "        print(f\"ðŸ™ï¸ Noms de villes normalisÃ©s\")\n",
    "    \n",
    "    # 4. DÃ©tection et traitement des outliers pour l'Ã¢ge\n",
    "    if 'Ã¢ge' in df_clean.columns:\n",
    "        Q1 = df_clean['Ã¢ge'].quantile(0.25)\n",
    "        Q3 = df_clean['Ã¢ge'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_before = len(df_clean)\n",
    "        df_clean = df_clean[(df_clean['Ã¢ge'] >= lower_bound) & (df_clean['Ã¢ge'] <= upper_bound)]\n",
    "        outliers_removed = outliers_before - len(df_clean)\n",
    "        print(f\"ðŸ“Š Outliers d'Ã¢ge supprimÃ©s: {outliers_removed}\")\n",
    "    \n",
    "    print(f\"âœ… Nettoyage terminÃ©. Taille finale: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "# Application du nettoyage\n",
    "df_clean = advanced_data_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989eaac1-0696-4274-b654-048c30414cb6",
   "metadata": {},
   "source": [
    "# ENCODAGE INTELLIGENT DES VARIABLES CATÃ‰GORIELLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ae511-f5df-4406-8a22-a7701dfda33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_encoding(df):\n",
    "   \n",
    "    df_encoded = df.copy()\n",
    "    encoders_dict = {}\n",
    "    \n",
    "    print(\"ðŸ”¢ ENCODAGE DES VARIABLES CATÃ‰GORIELLES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    categorical_columns = df_encoded.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        print(f\"ðŸ”¤ Encodage de '{col}'...\")\n",
    "        \n",
    "        # VÃ©rification du nombre de catÃ©gories uniques\n",
    "        unique_values = df_encoded[col].nunique()\n",
    "        print(f\"   â†’ {unique_values} valeurs uniques\")\n",
    "        \n",
    "        # Encodage avec LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        encoders_dict[col] = le\n",
    "        \n",
    "        # Affichage du mapping pour les colonnes importantes\n",
    "        if unique_values <= 10:\n",
    "            mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            print(f\"   â†’ Mapping: {mapping}\")\n",
    "    \n",
    "    print(f\"âœ… Encodage terminÃ© pour {len(categorical_columns)} colonnes\")\n",
    "    return df_encoded, encoders_dict\n",
    "\n",
    "# Application de l'encodage\n",
    "df_encoded, label_encoders = smart_encoding(df_clean)\n",
    "\n",
    "# VÃ©rification du rÃ©sultat\n",
    "print(\"\\nðŸ“‹ INFORMATIONS POST-ENCODAGE:\")\n",
    "print(\"=\" * 50)\n",
    "print(df_encoded.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae4109-ee24-42b1-8dbf-a373de31f10e",
   "metadata": {},
   "source": [
    "# ANALYSE EXPLORATOIRE APPROFONDIE DES DONNÃ‰ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c943f64-846e-4dae-b073-84beff602981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_eda(df):\n",
    "   \n",
    "    print(\"ðŸ“Š ANALYSE EXPLORATOIRE DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Distribution de l'Ã¢ge\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(data=df, x='Ã¢ge', kde=True, bins=30)\n",
    "    plt.title(\"Distribution des Ã¢ges\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Ã‚ge\")\n",
    "    plt.ylabel(\"FrÃ©quence\")\n",
    "    \n",
    "    # 2. RÃ©partition par sexe\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sex_counts = df['sexe'].value_counts()\n",
    "    plt.pie(sex_counts.values, labels=['Homme', 'Femme'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(\"RÃ©partition par sexe\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Variable cible\n",
    "    plt.subplot(1, 3, 3)\n",
    "    target_counts = df['Don_de_sang'].value_counts()\n",
    "    colors = ['lightcoral', 'lightblue']\n",
    "    plt.pie(target_counts.values, labels=['Non-donneur', 'Donneur'], \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title(\"RÃ©partition des donneurs\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Distribution par rÃ©gion\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    region_counts = df['rÃ©gion'].value_counts().head(15)\n",
    "    sns.barplot(x=region_counts.values, y=region_counts.index, palette='viridis')\n",
    "    plt.title(\"Top 15 des rÃ©gions par nombre de participants\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Nombre de participants\")\n",
    "    plt.ylabel(\"RÃ©gion\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Analyse des corrÃ©lations\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title(\"Matrice de corrÃ©lation\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Analyse bivariÃ©e avec la variable cible\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Ã‚ge vs Don de sang\n",
    "    plt.subplot(2, 3, 1)\n",
    "    sns.boxplot(data=df, x='Don_de_sang', y='Ã¢ge')\n",
    "    plt.title(\"Ã‚ge par statut de don\")\n",
    "    plt.xlabel(\"Don de sang (0=Non, 1=Oui)\")\n",
    "    \n",
    "    # Sexe vs Don de sang\n",
    "    plt.subplot(2, 3, 2)\n",
    "    ct = pd.crosstab(df['sexe'], df['Don_de_sang'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title(\"Taux de don par sexe (%)\")\n",
    "    plt.xlabel(\"Sexe\")\n",
    "    plt.ylabel(\"Pourcentage\")\n",
    "    plt.legend(['Non-donneur', 'Donneur'])\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques descriptives par groupe\n",
    "    print(\"\\nðŸ“ˆ STATISTIQUES PAR GROUPE:\")\n",
    "    print(\"=\" * 50)\n",
    "    stats_by_group = df.groupby('Don_de_sang')['Ã¢ge'].describe()\n",
    "    print(stats_by_group)\n",
    "\n",
    "# ExÃ©cution de l'EDA\n",
    "comprehensive_eda(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75b19a-38ff-4d94-a699-cd7613425d4b",
   "metadata": {},
   "source": [
    "# PRÃ‰PARATION DES DONNÃ‰ES POUR LA MODÃ‰LISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4169c-7298-4263-8ea9-08be6783bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_modeling_data(df, target_column='Don_de_sang', test_size=0.2, random_state=42):\n",
    "    \n",
    "    print(\"ðŸŽ¯ PRÃ‰PARATION DES DONNÃ‰ES POUR LA MODÃ‰LISATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # SÃ©paration des features et de la cible\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    print(f\"ðŸ“Š Nombre de features: {X.shape[1]}\")\n",
    "    print(f\"ðŸŽ¯ Distribution de la variable cible:\")\n",
    "    print(y.value_counts(normalize=True))\n",
    "    \n",
    "    # Division train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Division des donnÃ©es:\")\n",
    "    print(f\"   â†’ Training set: {X_train.shape[0]} Ã©chantillons\")\n",
    "    print(f\"   â†’ Test set: {X_test.shape[0]} Ã©chantillons\")\n",
    "    \n",
    "    # Normalisation des donnÃ©es (optionnel mais recommandÃ©)\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# PrÃ©paration des donnÃ©es\n",
    "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler = prepare_modeling_data(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2fb9e2-edbc-48fe-aa54-5c2a65f0e95d",
   "metadata": {},
   "source": [
    "# MODÃ‰LISATION MACHINE LEARNING AVANCÃ‰E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dccce-d546-4085-befc-b763c07d48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelEvaluator:\n",
    "   \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "    \n",
    "    def evaluate_model(self, name, model, X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Ã‰value un modÃ¨le de maniÃ¨re complÃ¨te\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ¤– Ã‰VALUATION DU MODÃˆLE: {name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # EntraÃ®nement\n",
    "        start_time = datetime.now()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # PrÃ©dictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # MÃ©triques de base\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='accuracy')\n",
    "        \n",
    "        # AUC-ROC si probabilitÃ©s disponibles\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "        \n",
    "        # Stockage des rÃ©sultats\n",
    "        self.results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc_roc,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'training_time': training_time,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        self.models[name] = model\n",
    "        \n",
    "        # Affichage des rÃ©sultats\n",
    "        print(f\"ðŸ“Š Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"ðŸŽ¯ Precision: {precision:.4f}\")\n",
    "        print(f\"ðŸ” Recall: {recall:.4f}\")\n",
    "        print(f\"âš–ï¸ F1-Score: {f1:.4f}\")\n",
    "        if auc_roc:\n",
    "            print(f\"ðŸ“ˆ AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(f\"ðŸ”„ CV Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "        print(f\"â±ï¸ Training Time: {training_time:.2f}s\")\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Rapport de classification:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def plot_confusion_matrices(self, y_test):\n",
    "        \n",
    "        n_models = len(self.results)\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (name, results) in enumerate(self.results.items()):\n",
    "            if i < len(axes):\n",
    "                cm = confusion_matrix(y_test, results['predictions'])\n",
    "                sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "                axes[i].set_title(f'Matrice de confusion - {name}')\n",
    "                axes[i].set_xlabel('PrÃ©dictions')\n",
    "                axes[i].set_ylabel('Valeurs rÃ©elles')\n",
    "        \n",
    "        # Masquer les axes inutilisÃ©s\n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curves(self, y_test):\n",
    "       \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for name, results in self.results.items():\n",
    "            if results['probabilities'] is not None:\n",
    "                fpr, tpr, _ = roc_curve(y_test, results['probabilities'])\n",
    "                auc = results['auc_roc']\n",
    "                plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        plt.xlabel('Taux de Faux Positifs')\n",
    "        plt.ylabel('Taux de Vrais Positifs')\n",
    "        plt.title('Courbes ROC - Comparaison des modÃ¨les')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_results_summary(self):\n",
    "       \n",
    "        results_df = pd.DataFrame(self.results).T\n",
    "        results_df = results_df.round(4)\n",
    "        return results_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "# Initialisation de l'Ã©valuateur\n",
    "evaluator = MLModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f05f9-ad2f-4bee-9b10-945f3b2845c3",
   "metadata": {},
   "source": [
    "# ENTRAÃŽNEMENT ET Ã‰VALUATION DES MODÃˆLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c50d1b-caad-45b8-80b2-2876b7377dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. RÃ©gression Logistique\n",
    "print(\"ðŸš€ DÃ‰MARRAGE DE LA MODÃ‰LISATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "evaluator.evaluate_model(\"RÃ©gression Logistique\", lr_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "evaluator.evaluate_model(\"K-Nearest Neighbors\", knn_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 3. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluator.evaluate_model(\"Random Forest\", rf_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "evaluator.evaluate_model(\"Support Vector Machine\", svm_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 5. XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "evaluator.evaluate_model(\"XGBoost\", xgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 6. LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "evaluator.evaluate_model(\"LightGBM\", lgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 7. CatBoost\n",
    "cat_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "evaluator.evaluate_model(\"CatBoost\", cat_model, X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31218c5c-5455-42e0-a9d4-987e8c7b8a4b",
   "metadata": {},
   "source": [
    "# ANALYSE COMPARATIVE DES RÃ‰SULTATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b475e-8e46-43a1-a09c-aad3fc802690",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ† RÃ‰SUMÃ‰ COMPARATIF DES PERFORMANCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tableau comparatif\n",
    "results_summary = evaluator.get_results_summary()\n",
    "print(results_summary)\n",
    "\n",
    "# Visualisations comparatives\n",
    "evaluator.plot_confusion_matrices(y_test)\n",
    "evaluator.plot_roc_curves(y_test)\n",
    "\n",
    "# Graphique comparatif des mÃ©triques principales\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "model_names = list(evaluator.results.keys())\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    values = [evaluator.results[model][metric] for model in model_names]\n",
    "    bars = plt.bar(model_names, values, alpha=0.8)\n",
    "    plt.title(f'Comparaison - {metric.upper()}')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76615d30-5e09-418c-9e48-629302652d55",
   "metadata": {},
   "source": [
    "#  OPTIMISATION DU MEILLEUR MODÃˆLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d4311-7f18-4626-a283-8b0908fb2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_best_model(evaluator, X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    # Identifier le meilleur modÃ¨le\n",
    "    best_model_name = evaluator.get_results_summary().index[0]\n",
    "    print(f\"\\nðŸŽ¯ OPTIMISATION DU MEILLEUR MODÃˆLE: {best_model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if \"XGBoost\" in best_model_name:\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "        \n",
    "    elif \"Random Forest\" in best_model_name:\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    else:\n",
    "        print(\"Optimisation non implÃ©mentÃ©e pour ce modÃ¨le\")\n",
    "        return None\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid, cv=5, scoring='accuracy', \n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"ðŸ† Meilleurs paramÃ¨tres: {grid_search.best_params_}\")\n",
    "    print(f\"ðŸ“Š Meilleur score CV: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Ã‰valuation du modÃ¨le optimisÃ©\n",
    "    optimized_model = grid_search.best_estimator_\n",
    "    evaluator.evaluate_model(f\"{best_model_name} (OptimisÃ©)\", \n",
    "                           optimized_model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    return optimized_model\n",
    "\n",
    "# Optimisation du meilleur modÃ¨le\n",
    "best_optimized_model = optimize_best_model(evaluator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddb62a-e402-42a4-80dc-1c288aee01f9",
   "metadata": {},
   "source": [
    "# ANALYSE DE L'IMPORTANCE DES VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3cb63-ae82-40b4-9dda-e96259a9c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, feature_names, model_name):\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(f\"\\nðŸ” IMPORTANCE DES VARIABLES - {model_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "        # Visualisation\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(15)\n",
    "        sns.barplot(data=top_features, x='Importance', y='Variable')\n",
    "        plt.title(f'Top 15 Variables les plus importantes - {model_name}')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    else:\n",
    "        print(f\"Le modÃ¨le {model_name} ne supporte pas l'analyse d'importance des variables\")\n",
    "        return None\n",
    "\n",
    "# Analyse pour les modÃ¨les basÃ©s sur les arbres\n",
    "feature_names = X_train.columns\n",
    "for name, model in evaluator.models.items():\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        analyze_feature_importance(model, feature_names, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381b6f9-b156-48e9-895e-ac9c62a5d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
