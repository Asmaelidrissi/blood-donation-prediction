{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74b5ee0-00ab-4018-9053-def788518bf7",
   "metadata": {},
   "source": [
    "# Prédiction du Comportement des Donneurs de Sang\n",
    "\n",
    "Projet de fin d'année – ENSIAS BI&A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cfb21-cbd7-4f85-b580-007a4ccc0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppression des avertissements\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Librairies de preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (classification_report, accuracy_score, confusion_matrix, \n",
    "                           roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                           f1_score, precision_score, recall_score)\n",
    "\n",
    "# Modèles de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "print(\"✅ Toutes les bibliothèques ont été importées avec succès!\")\n",
    "print(f\"📅 Session démarrée le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd0bda-d05b-4244-a3ea-9c1f89d9a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_inspect_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"✅ Dataset chargé avec succès!\")\n",
    "        print(f\"📊 Dimensions: {df.shape[0]} lignes × {df.shape[1]} colonnes\\n\")\n",
    "        \n",
    "        # Affichage des informations de base\n",
    "        print(\"🔍 APERÇU DES DONNÉES:\")\n",
    "        print(\"=\" * 50)\n",
    "        display(df.head())\n",
    "        \n",
    "        print(\"\\n📈 INFORMATIONS GÉNÉRALES:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(df.info())\n",
    "        \n",
    "        print(\"\\n📊 STATISTIQUES DESCRIPTIVES:\")\n",
    "        print(\"=\" * 50)\n",
    "        display(df.describe(include='all'))\n",
    "        \n",
    "        print(\"\\n❌ VALEURS MANQUANTES:\")\n",
    "        print(\"=\" * 50)\n",
    "        missing_data = df.isnull().sum()\n",
    "        missing_percent = (missing_data / len(df)) * 100\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Colonne': missing_data.index,\n",
    "            'Valeurs manquantes': missing_data.values,\n",
    "            'Pourcentage': missing_percent.values\n",
    "        }).sort_values('Valeurs manquantes', ascending=False)\n",
    "        \n",
    "        display(missing_df[missing_df['Valeurs manquantes'] > 0])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement: {e}\")\n",
    "        return None\n",
    "\n",
    "# Chargement des données\n",
    "df = load_and_inspect_data(\"base1_nettoyee.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb1f12-9ede-419f-a632-9d8b197222a1",
   "metadata": {},
   "source": [
    "#  NETTOYAGE ET PRÉPROCESSING AVANCÉ DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74bed8-29ef-40b2-836f-1ba9bdf9cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_data_cleaning(df):\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"🧹 NETTOYAGE DES DONNÉES EN COURS...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Suppression des doublons\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean.drop_duplicates(inplace=True)\n",
    "    duplicates_removed = initial_rows - len(df_clean)\n",
    "    print(f\"🔄 Doublons supprimés: {duplicates_removed}\")\n",
    "    \n",
    "    # 2. Gestion des valeurs manquantes\n",
    "    missing_before = df_clean.isnull().sum().sum()\n",
    "    df_clean.dropna(inplace=True)\n",
    "    missing_after = df_clean.isnull().sum().sum()\n",
    "    print(f\"❌ Valeurs manquantes supprimées: {missing_before - missing_after}\")\n",
    "    \n",
    "    # 3. Normalisation des noms de villes (avec gestion d'erreurs)\n",
    "    if 'Ville  المدينة' in df_clean.columns:\n",
    "        ville_mapping = {\n",
    "            'RABAT': 'Rabat', 'rabat': 'Rabat',\n",
    "            'Casa': 'Casablanca', 'casa': 'Casablanca', 'CASA': 'Casablanca',\n",
    "            'AGADIR': 'Agadir', 'agadir': 'Agadir',\n",
    "            'FES': 'Fès', 'fes': 'Fès', 'Fes': 'Fès',\n",
    "            'MARRAKECH': 'Marrakech', 'marrakech': 'Marrakech',\n",
    "            'TANGER': 'Tanger', 'tanger': 'Tanger'\n",
    "        }\n",
    "        df_clean['Ville  المدينة'] = df_clean['Ville  المدينة'].replace(ville_mapping)\n",
    "        print(f\"🏙️ Noms de villes normalisés\")\n",
    "    \n",
    "    # 4. Détection et traitement des outliers pour l'âge\n",
    "    if 'âge' in df_clean.columns:\n",
    "        Q1 = df_clean['âge'].quantile(0.25)\n",
    "        Q3 = df_clean['âge'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_before = len(df_clean)\n",
    "        df_clean = df_clean[(df_clean['âge'] >= lower_bound) & (df_clean['âge'] <= upper_bound)]\n",
    "        outliers_removed = outliers_before - len(df_clean)\n",
    "        print(f\"📊 Outliers d'âge supprimés: {outliers_removed}\")\n",
    "    \n",
    "    print(f\"✅ Nettoyage terminé. Taille finale: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "# Application du nettoyage\n",
    "df_clean = advanced_data_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989eaac1-0696-4274-b654-048c30414cb6",
   "metadata": {},
   "source": [
    "# ENCODAGE INTELLIGENT DES VARIABLES CATÉGORIELLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ae511-f5df-4406-8a22-a7701dfda33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_encoding(df):\n",
    "   \n",
    "    df_encoded = df.copy()\n",
    "    encoders_dict = {}\n",
    "    \n",
    "    print(\"🔢 ENCODAGE DES VARIABLES CATÉGORIELLES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    categorical_columns = df_encoded.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        print(f\"🔤 Encodage de '{col}'...\")\n",
    "        \n",
    "        # Vérification du nombre de catégories uniques\n",
    "        unique_values = df_encoded[col].nunique()\n",
    "        print(f\"   → {unique_values} valeurs uniques\")\n",
    "        \n",
    "        # Encodage avec LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        encoders_dict[col] = le\n",
    "        \n",
    "        # Affichage du mapping pour les colonnes importantes\n",
    "        if unique_values <= 10:\n",
    "            mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            print(f\"   → Mapping: {mapping}\")\n",
    "    \n",
    "    print(f\"✅ Encodage terminé pour {len(categorical_columns)} colonnes\")\n",
    "    return df_encoded, encoders_dict\n",
    "\n",
    "# Application de l'encodage\n",
    "df_encoded, label_encoders = smart_encoding(df_clean)\n",
    "\n",
    "# Vérification du résultat\n",
    "print(\"\\n📋 INFORMATIONS POST-ENCODAGE:\")\n",
    "print(\"=\" * 50)\n",
    "print(df_encoded.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae4109-ee24-42b1-8dbf-a373de31f10e",
   "metadata": {},
   "source": [
    "# ANALYSE EXPLORATOIRE APPROFONDIE DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c943f64-846e-4dae-b073-84beff602981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_eda(df):\n",
    "   \n",
    "    print(\"📊 ANALYSE EXPLORATOIRE DES DONNÉES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Distribution de l'âge\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(data=df, x='âge', kde=True, bins=30)\n",
    "    plt.title(\"Distribution des âges\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Âge\")\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    \n",
    "    # 2. Répartition par sexe\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sex_counts = df['sexe'].value_counts()\n",
    "    plt.pie(sex_counts.values, labels=['Homme', 'Femme'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(\"Répartition par sexe\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Variable cible\n",
    "    plt.subplot(1, 3, 3)\n",
    "    target_counts = df['Don_de_sang'].value_counts()\n",
    "    colors = ['lightcoral', 'lightblue']\n",
    "    plt.pie(target_counts.values, labels=['Non-donneur', 'Donneur'], \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title(\"Répartition des donneurs\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Distribution par région\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    region_counts = df['région'].value_counts().head(15)\n",
    "    sns.barplot(x=region_counts.values, y=region_counts.index, palette='viridis')\n",
    "    plt.title(\"Top 15 des régions par nombre de participants\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Nombre de participants\")\n",
    "    plt.ylabel(\"Région\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Analyse des corrélations\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title(\"Matrice de corrélation\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Analyse bivariée avec la variable cible\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Âge vs Don de sang\n",
    "    plt.subplot(2, 3, 1)\n",
    "    sns.boxplot(data=df, x='Don_de_sang', y='âge')\n",
    "    plt.title(\"Âge par statut de don\")\n",
    "    plt.xlabel(\"Don de sang (0=Non, 1=Oui)\")\n",
    "    \n",
    "    # Sexe vs Don de sang\n",
    "    plt.subplot(2, 3, 2)\n",
    "    ct = pd.crosstab(df['sexe'], df['Don_de_sang'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title(\"Taux de don par sexe (%)\")\n",
    "    plt.xlabel(\"Sexe\")\n",
    "    plt.ylabel(\"Pourcentage\")\n",
    "    plt.legend(['Non-donneur', 'Donneur'])\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques descriptives par groupe\n",
    "    print(\"\\n📈 STATISTIQUES PAR GROUPE:\")\n",
    "    print(\"=\" * 50)\n",
    "    stats_by_group = df.groupby('Don_de_sang')['âge'].describe()\n",
    "    print(stats_by_group)\n",
    "\n",
    "# Exécution de l'EDA\n",
    "comprehensive_eda(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75b19a-38ff-4d94-a699-cd7613425d4b",
   "metadata": {},
   "source": [
    "# PRÉPARATION DES DONNÉES POUR LA MODÉLISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4169c-7298-4263-8ea9-08be6783bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_modeling_data(df, target_column='Don_de_sang', test_size=0.2, random_state=42):\n",
    "    \n",
    "    print(\"🎯 PRÉPARATION DES DONNÉES POUR LA MODÉLISATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Séparation des features et de la cible\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    print(f\"📊 Nombre de features: {X.shape[1]}\")\n",
    "    print(f\"🎯 Distribution de la variable cible:\")\n",
    "    print(y.value_counts(normalize=True))\n",
    "    \n",
    "    # Division train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Division des données:\")\n",
    "    print(f\"   → Training set: {X_train.shape[0]} échantillons\")\n",
    "    print(f\"   → Test set: {X_test.shape[0]} échantillons\")\n",
    "    \n",
    "    # Normalisation des données (optionnel mais recommandé)\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Préparation des données\n",
    "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler = prepare_modeling_data(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2fb9e2-edbc-48fe-aa54-5c2a65f0e95d",
   "metadata": {},
   "source": [
    "# MODÉLISATION MACHINE LEARNING AVANCÉE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dccce-d546-4085-befc-b763c07d48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelEvaluator:\n",
    "   \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "    \n",
    "    def evaluate_model(self, name, model, X_train, X_test, y_train, y_test, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Évalue un modèle de manière complète\n",
    "        \"\"\"\n",
    "        print(f\"\\n🤖 ÉVALUATION DU MODÈLE: {name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Entraînement\n",
    "        start_time = datetime.now()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Prédictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Métriques de base\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='accuracy')\n",
    "        \n",
    "        # AUC-ROC si probabilités disponibles\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "        \n",
    "        # Stockage des résultats\n",
    "        self.results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc_roc,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'training_time': training_time,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        self.models[name] = model\n",
    "        \n",
    "        # Affichage des résultats\n",
    "        print(f\"📊 Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"🎯 Precision: {precision:.4f}\")\n",
    "        print(f\"🔍 Recall: {recall:.4f}\")\n",
    "        print(f\"⚖️ F1-Score: {f1:.4f}\")\n",
    "        if auc_roc:\n",
    "            print(f\"📈 AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(f\"🔄 CV Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "        print(f\"⏱️ Training Time: {training_time:.2f}s\")\n",
    "        \n",
    "        print(f\"\\n📋 Rapport de classification:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def plot_confusion_matrices(self, y_test):\n",
    "        \n",
    "        n_models = len(self.results)\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (name, results) in enumerate(self.results.items()):\n",
    "            if i < len(axes):\n",
    "                cm = confusion_matrix(y_test, results['predictions'])\n",
    "                sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "                axes[i].set_title(f'Matrice de confusion - {name}')\n",
    "                axes[i].set_xlabel('Prédictions')\n",
    "                axes[i].set_ylabel('Valeurs réelles')\n",
    "        \n",
    "        # Masquer les axes inutilisés\n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curves(self, y_test):\n",
    "       \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for name, results in self.results.items():\n",
    "            if results['probabilities'] is not None:\n",
    "                fpr, tpr, _ = roc_curve(y_test, results['probabilities'])\n",
    "                auc = results['auc_roc']\n",
    "                plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        plt.xlabel('Taux de Faux Positifs')\n",
    "        plt.ylabel('Taux de Vrais Positifs')\n",
    "        plt.title('Courbes ROC - Comparaison des modèles')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_results_summary(self):\n",
    "       \n",
    "        results_df = pd.DataFrame(self.results).T\n",
    "        results_df = results_df.round(4)\n",
    "        return results_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "# Initialisation de l'évaluateur\n",
    "evaluator = MLModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f05f9-ad2f-4bee-9b10-945f3b2845c3",
   "metadata": {},
   "source": [
    "# ENTRAÎNEMENT ET ÉVALUATION DES MODÈLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c50d1b-caad-45b8-80b2-2876b7377dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Régression Logistique\n",
    "print(\"🚀 DÉMARRAGE DE LA MODÉLISATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "evaluator.evaluate_model(\"Régression Logistique\", lr_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "evaluator.evaluate_model(\"K-Nearest Neighbors\", knn_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 3. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluator.evaluate_model(\"Random Forest\", rf_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "evaluator.evaluate_model(\"Support Vector Machine\", svm_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# 5. XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "evaluator.evaluate_model(\"XGBoost\", xgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 6. LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "evaluator.evaluate_model(\"LightGBM\", lgb_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 7. CatBoost\n",
    "cat_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "evaluator.evaluate_model(\"CatBoost\", cat_model, X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31218c5c-5455-42e0-a9d4-987e8c7b8a4b",
   "metadata": {},
   "source": [
    "# ANALYSE COMPARATIVE DES RÉSULTATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b475e-8e46-43a1-a09c-aad3fc802690",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🏆 RÉSUMÉ COMPARATIF DES PERFORMANCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tableau comparatif\n",
    "results_summary = evaluator.get_results_summary()\n",
    "print(results_summary)\n",
    "\n",
    "# Visualisations comparatives\n",
    "evaluator.plot_confusion_matrices(y_test)\n",
    "evaluator.plot_roc_curves(y_test)\n",
    "\n",
    "# Graphique comparatif des métriques principales\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "model_names = list(evaluator.results.keys())\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    values = [evaluator.results[model][metric] for model in model_names]\n",
    "    bars = plt.bar(model_names, values, alpha=0.8)\n",
    "    plt.title(f'Comparaison - {metric.upper()}')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76615d30-5e09-418c-9e48-629302652d55",
   "metadata": {},
   "source": [
    "#  OPTIMISATION DU MEILLEUR MODÈLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d4311-7f18-4626-a283-8b0908fb2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_best_model(evaluator, X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    # Identifier le meilleur modèle\n",
    "    best_model_name = evaluator.get_results_summary().index[0]\n",
    "    print(f\"\\n🎯 OPTIMISATION DU MEILLEUR MODÈLE: {best_model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if \"XGBoost\" in best_model_name:\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "        \n",
    "    elif \"Random Forest\" in best_model_name:\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    else:\n",
    "        print(\"Optimisation non implémentée pour ce modèle\")\n",
    "        return None\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid, cv=5, scoring='accuracy', \n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"🏆 Meilleurs paramètres: {grid_search.best_params_}\")\n",
    "    print(f\"📊 Meilleur score CV: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Évaluation du modèle optimisé\n",
    "    optimized_model = grid_search.best_estimator_\n",
    "    evaluator.evaluate_model(f\"{best_model_name} (Optimisé)\", \n",
    "                           optimized_model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    return optimized_model\n",
    "\n",
    "# Optimisation du meilleur modèle\n",
    "best_optimized_model = optimize_best_model(evaluator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddb62a-e402-42a4-80dc-1c288aee01f9",
   "metadata": {},
   "source": [
    "# ANALYSE DE L'IMPORTANCE DES VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3cb63-ae82-40b4-9dda-e96259a9c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, feature_names, model_name):\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(f\"\\n🔍 IMPORTANCE DES VARIABLES - {model_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'Variable': feature_names,\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "        # Visualisation\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(15)\n",
    "        sns.barplot(data=top_features, x='Importance', y='Variable')\n",
    "        plt.title(f'Top 15 Variables les plus importantes - {model_name}')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "    else:\n",
    "        print(f\"Le modèle {model_name} ne supporte pas l'analyse d'importance des variables\")\n",
    "        return None\n",
    "\n",
    "# Analyse pour les modèles basés sur les arbres\n",
    "feature_names = X_train.columns\n",
    "for name, model in evaluator.models.items():\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        analyze_feature_importance(model, feature_names, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381b6f9-b156-48e9-895e-ac9c62a5d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
